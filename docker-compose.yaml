version: '2'

services:
  # Serviço do SQL Server com CDC habilitado
  sqlserver:
    build:
      context: ./sqlserver-custom
      dockerfile: Dockerfile
    image: meu-sql-server-template:latest
    ports:
      - 1433:1433
    env_file:
      - .env
    environment:
      SA_PASSWORD: ${SQLSERVER_PASSWORD}
      ACCEPT_EULA: "Y"
      MSSQL_PID: Developer
      MSSQL_AGENT_ENABLED: "true"
    volumes:
      - sqlserver_data:/var/opt/mssql
    restart: unless-stopped

  # Serviço Zookeeper (necessário para o Kafka funcionar)
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    depends_on:
      - sqlserver
    ports:
      - 2181:2181
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    restart: unless-stopped

  # Serviço do Kafka
  kafka:
    image: confluentinc/cp-kafka:latest
    depends_on:
      - sqlserver
      - zookeeper
    ports:
      - 9092:9092
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    restart: unless-stopped

  # Interface Web para visualizar os tópicos do Kafka
  kafdrop:
    image: obsidiandynamics/kafdrop:latest
    depends_on:
      - kafka
    ports:
      - 19000:9000
    environment:
      KAFKA_BROKERCONNECT: kafka:9092
    restart: unless-stopped

  # Kafka Connect com Debezium
  connect:
    build: ./connect
    image: cdc:latest
    depends_on:
      - sqlserver
      - kafka
    ports:
      - 8083:8083
    environment:
      CONNECT_BOOTSTRAP_SERVERS: kafka:9092
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: connect-1
      CONNECT_CONFIG_STORAGE_TOPIC: connect-1-config
      CONNECT_OFFSET_STORAGE_TOPIC: connect-1-offsets
      CONNECT_STATUS_STORAGE_TOPIC: connect-1-status
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_OFFSET.STORAGE.REPLICATION.FACTOR: 1
      CONNECT_CONFIG.STORAGE.REPLICATION.FACTOR: 1
      CONNECT_OFFSET.STORAGE.PARTITIONS: 1
      CONNECT_STATUS.STORAGE.REPLICATION.FACTOR: 1
      CONNECT_STATUS.STORAGE.PARTITIONS: 1
      CONNECT_REST_ADVERTISED_HOST_NAME: connect
      CONNECT_PLUGIN_PATH: /usr/share/confluent-hub-components
    volumes:
      - connect_data:/kafka/connect
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8083/"]
      interval: 10s
      timeout: 5s
      retries: 10

  # Serviço responsável por carregar automaticamente os conectores via Python
  connect-loader:
    build:
      context: ./connect-loader
    depends_on:
      connect:
        condition: service_healthy
    env_file:
      - .env
    command: ["python", "connectores.py"]  
    restart: on-failure

  # Consumer Python que lê os dados do tópico e envia alertas para o Telegram
  consumer:
    build:
      context: ./consumer
    depends_on:
       kafka:
        condition: service_started
       connect:
        condition: service_healthy
    env_file:
      - ./consumer/.env
    restart: unless-stopped

# Volumes persistentes
volumes:
  sqlserver_data:
  connect_data:
